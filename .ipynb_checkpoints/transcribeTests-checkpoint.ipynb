{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minimal-preserve",
   "metadata": {},
   "source": [
    "# Score Transcriptions with IPA and no IPA\n",
    "### Install python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "composed-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Unidecode\n",
      "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: Unidecode\n",
      "Successfully installed Unidecode-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-fiction",
   "metadata": {},
   "source": [
    "# Import Pyhthon Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "developing-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import boto3\n",
    "import sys, os\n",
    "from datetime import date, timedelta, datetime, timezone\n",
    "import time \n",
    "import numpy as np\n",
    "import random\n",
    "import tarfile\n",
    "import unidecode as uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-underwear",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-knock",
   "metadata": {},
   "source": [
    "### Function to get file name from S3 buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "certified-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_s3_objects(s3, **base_kwargs):\n",
    "    ###\n",
    "    #   Function to amplify the limit of AWS results to 1000+\n",
    "    ###\n",
    "    continuation_token = None\n",
    "    while True:\n",
    "        list_kwargs = dict(MaxKeys=1000, **base_kwargs)\n",
    "        if continuation_token:\n",
    "            list_kwargs['ContinuationToken'] = continuation_token\n",
    "        response = s3.list_objects_v2(**list_kwargs)\n",
    "        yield from response.get('Contents', [])\n",
    "        if not response.get('IsTruncated'):  # At the end of the list?\n",
    "            break\n",
    "        continuation_token = response.get('NextContinuationToken')\n",
    "\n",
    "def get_folder_list(bucket='awstranscribe-tests', key='transcribeOutputs/Files'):\n",
    "    ###\n",
    "    #  Get the name of the files in a bucket. While bucket is the AWS S3 Bucket and key is the folder inside that bucket\n",
    "    # it defaults to transcribeOutputs/Files\n",
    "    ###\n",
    "    s3 = boto3.client('s3')\n",
    "    data_loc = []\n",
    "    for obj in get_all_s3_objects(s3, Bucket=bucket, Prefix=key):\n",
    "        names = 's3://{}/{}'.format(bucket, obj['Key'])\n",
    "        data_loc.append(names)\n",
    "    return data_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-africa",
   "metadata": {},
   "source": [
    "### Function to create a .csv file from a Pandas DataFrame\n",
    "Creates a file into a definded AWS S3 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "equivalent-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(df, file_name=date.today()):\n",
    "    today = date.today()\n",
    "    csv_buffer = StringIO()\n",
    "    data_frame = df\n",
    "    data_frame.to_csv(csv_buffer, decimal='.', sep=',', encoding='utf-8', index=False, header=None)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object('awstranscribe-tests', f'transcribeOutputs/proc_files/{file_name}.csv').put(Body=csv_buffer.getvalue()) ## CHANGE temp_Mail for Mails\n",
    "    \n",
    "    return f'Saved as file: awstranscribe-tests/transcribeOutputs/proc_files/{file_name}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-capability",
   "metadata": {},
   "source": [
    "### Function to neutralize words\n",
    "Remove accent characters and lowercase the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "welcome-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize(a_string):\n",
    "    a_string = uni.unidecode(a_string)\n",
    "    a_string = a_string.replace('?', '')\n",
    "    return a_string.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-coral",
   "metadata": {},
   "source": [
    "### function that calculates percentage of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "southern-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(string_real, string_model, extra_info=False):\n",
    "    # cut strings to bag of words\n",
    "    words_real = neutralize(string_real).split(' ')\n",
    "    count = 0\n",
    "    error_words = []\n",
    "    for word in words_real:\n",
    "        # search word in string_model\n",
    "        if word in neutralize(string_model):\n",
    "            count = count + 1\n",
    "        else:\n",
    "            error_words.append(word)\n",
    "\n",
    "    score = count / len(words_real)\n",
    "    if extra_info:\n",
    "        return score, error_words\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-grenada",
   "metadata": {},
   "source": [
    "### Function that calculates the percentage of similarity words usaing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "suspended-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score_dataframes(_df_real, _df_model):\n",
    "    score_list = []\n",
    "\n",
    "    for a_file, a_string in zip(_df_model['file'], _df_model['transcript']):\n",
    "        # first, we search for file in real\n",
    "        real_str = _df_real[_df_real['file']==a_file]['transcript']\n",
    "\n",
    "        # files should be 1:1, if not, we riot\n",
    "        if len(real_str) != 1:\n",
    "            AttributeError('Dude files are not 1:1 in ' + a_file)\n",
    "\n",
    "        # otherwise let's continue calculating the score\n",
    "        #print(real_str.array)\n",
    "        score, fails = similarity_score(real_str.array[0], a_string, extra_info=True)\n",
    "        score_list.append((a_file, score, fails))\n",
    "\n",
    "    return pd.DataFrame(score_list, columns=['file', 'score', 'failed_words'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-alpha",
   "metadata": {},
   "source": [
    "# Testing executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "female-resolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43    alo? Buenos días. Habló con José? García Sepúl...\n",
      "Name: transcript, dtype: object\n",
      "43    malo. Buenos días. Habló con José? García Sepú...\n",
      "Name: transcript, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_real = get_folder_list(key='transcribeOutputs/proc_files/IPA')\n",
    "df_model = get_folder_list(key='transcribeOutputs/proc_files/no_IPA')\n",
    "\n",
    "for df_real_ in df_real[1:]:\n",
    "    df_real_1 = pd.read_csv(df_real_, names=['file', 'transcript'])\n",
    "\n",
    "for df_model_ in df_model[1:]:\n",
    "    df_model_1 = pd.read_csv(df_model_, names=['file', 'transcript'])\n",
    "\n",
    "    \n",
    "scr_list = similarity_score_dataframes(df_real_1, df_model_1)\n",
    "\n",
    "\n",
    "print(df_real_1.loc[df_real_1['file'] == '101233987_957841393_100174498730201118_20201118_124750_1001744989_1001744987_13139a7ae50fc843b1dadd0c_.json']['transcript'])\n",
    "print(df_model_1.loc[df_model_1['file'] == '101233987_957841393_100174498730201118_20201118_124750_1001744989_1001744987_13139a7ae50fc843b1dadd0c_.json']['transcript'])\n",
    "\n",
    "\n",
    "\n",
    "#Qto_file(scr_list, file_name='Testing01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-progressive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
