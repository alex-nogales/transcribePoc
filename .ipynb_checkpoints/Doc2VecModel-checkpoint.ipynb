{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "norman-evaluation",
   "metadata": {},
   "source": [
    "# Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "invalid-international",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 8.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-Levenshtein) (51.1.2)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp36-cp36m-linux_x86_64.whl size=155943 sha256=8ec53e88e3aefbd11f14763e33224cf57c50b4f3176b180c65333123879f89b8\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/4a/a4/bf/d761b0899395c75fa76d003d607b3869ee47f5035b8afc30a2\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.12.2\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "protecting-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "import gensim\n",
    "import os\n",
    "import smart_open\n",
    "import Levenshtein\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "lee_train_file = 's3://awstranscribe-tests/doc2vec/corpus.cor'\n",
    "lee_test_file = 's3://awstranscribe-tests/transcribeOutputs/proc_files/no_IPA/test_file.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-stations",
   "metadata": {},
   "source": [
    "### Read and process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vertical-growth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['alo', 'buenas', 'tardes', 'hablã³', 'con', 'don', 'jorge', 'cadenas', 'kilos', 'favor', 'diga', 'sã', 'no', 'alo', 'no', 'se', 'debemos', 'disculpe', 'pero', 'usted', 'don', 'jorge', 'cadenas', 'quiero'], tags=[0]), TaggedDocument(words=['alo', 'buenas', 'tardes', 'hablã³', 'con', 'don', 'hã', 'ctor', 'arriagada', 'cabello', 'favor', 'diga', 'sã', 'no'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "                \n",
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))\n",
    "print(train_corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-relaxation",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recognized-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-17 12:23:23,866 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2021-02-17 12:23:23,868 : INFO : collecting all words and their counts\n",
      "2021-02-17 12:23:23,869 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2021-02-17 12:23:23,870 : INFO : collected 300 word types and 50 unique tags from a corpus of 50 examples and 1937 words\n",
      "2021-02-17 12:23:23,871 : INFO : Loading a fresh vocabulary\n",
      "2021-02-17 12:23:23,872 : INFO : effective_min_count=2 retains 161 unique words (53% of original 300, drops 139)\n",
      "2021-02-17 12:23:23,872 : INFO : effective_min_count=2 leaves 1798 word corpus (92% of original 1937, drops 139)\n",
      "2021-02-17 12:23:23,874 : INFO : deleting the raw counts dictionary of 300 items\n",
      "2021-02-17 12:23:23,875 : INFO : sample=0.001 downsamples 74 most-common words\n",
      "2021-02-17 12:23:23,876 : INFO : downsampling leaves estimated 788 word corpus (43.9% of prior 1798)\n",
      "2021-02-17 12:23:23,877 : INFO : estimated required memory for 161 words and 50 dimensions: 154900 bytes\n",
      "2021-02-17 12:23:23,878 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "stopped-violence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.Doc2VecKeyedVectors"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.docvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-franchise",
   "metadata": {},
   "source": [
    "### Accesing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "defined-growing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-17 12:31:04,423 : INFO : precomputing L2-norms of doc weight vectors\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hollow-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({15: 5, 6: 3, 42: 3, 41: 3, 39: 3, 24: 2, 17: 2, 12: 2, 1: 2, 21: 2, 43: 2, 0: 1, 31: 1, 23: 1, 18: 1, 40: 1, 33: 1, 8: 1, 10: 1, 19: 1, 22: 1, 45: 1, 47: 1, 4: 1, 14: 1, 34: 1, 9: 1, 5: 1, 29: 1, 30: 1, 13: 1, 49: 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hispanic-heaven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (49): «alo buenos dã as hablã³ con doã roxana reta mal verdejo»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (3, 0.255410760641098): «alo buenos dã as hablã³ con don ronnie muã oz araya sã don ronnie habla con su ejecutiva virtual para su seguridad esta conversaciã³n podrã ser grabada le estamos llamando de socofin por encargo de banco de chile para informarle que se encuentra en pago su tarjeta de crã dito con fecha cuatro de noviembre de dos mil veinte si usted ya cancelã³ por favor omitir este mensaje que tenga un buen dã»\n",
      "\n",
      "SECOND-MOST (29, 0.21810851991176605): «alo buenas tardes hablã³ con don jorge hernã ndez haedo sã disculpe tenemos un mensaje importante es usted don jorge hernã ndez si disculpe tenemos un mensaje importante es usted don jorge hernã ndez favor diga sã no si don jorge habla con su ejecutiva virtual para su seguridad esta conversaciã³n podrã ser grabada le estamos llamando de socofin por encargo de banco de chile para informarle que se encuentra en pago crã dito renegociado con fecha cinco de noviembre de dos mil veinte si usted ya cancelã³ por favor omitir este mensaje que tenga un buen dã»\n",
      "\n",
      "MEDIAN (9, -0.017987478524446487): «alo buenas tardes hablã³ con julio llorente alo»\n",
      "\n",
      "LEAST (10, -0.28766870498657227): «alo buenas tardes hablã³ con don juan muã oz riquelme sã don juan habla con su ejecutiva virtual para su seguridad esta conversaciã³n podrã ser grabada le estamos llamando de socofin por encargo de banco credichile para informarle que se encuentra en pago su crã dito de consumo con fecha cinco de noviembre de dos mil veinte si usted ya cancelã³ por favor omitir este mensaje que tenga un buen dã»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "underlying-occupation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (2): «alo buenas tardes alo hablã³ con doã miriam acostara ya favor indica sã no»\n",
      "\n",
      "Similar Document (40, 0.29418909549713135): «alo buenos dã as hablã³ con don josã juan churrianero iba bien favor responder sã no no»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "determined-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.055944055944055944"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nice = 'alo? Buenas tardes. Habló con Don Jorge. Cadenas, kilos favor Diga sí o no. alo? No se debemos. Disculpe. Pero usted, Don Jorge Cadenas, quiero'\n",
    "bad = 'a lo buenas tardes. Habló con Don Jorge. Cadenas, kilos Favor, Diga sí o no. a No se debemos. Disculpe. Pero usted, Don Jorge Cadenas, quiero'\n",
    "\n",
    "## Lev / lawrgo de palabra  \n",
    "print(len(nice))\n",
    "Levenshtein.distance(nice, bad)  / len(nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-cycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
